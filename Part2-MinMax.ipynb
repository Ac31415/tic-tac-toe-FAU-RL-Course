{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A perfect Tic Tac Tow player, using the Min-Max algorithm #\n",
    "In this Notebook, we will use the Min-Max algorith to create a computer player which will be able to play Tic Tac Toe perfectly. That is, the player will always play the best move in a given situation. This player will give us a goodbench mark to pit the other players against.\n",
    "\n",
    "Let's start by importing a few of the utility functions and classes we defined last time and make sure it all works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "      border: 1px  black solid !important;\n",
       "      color: black !important;\n",
       "    }\n",
       "    </style>\n",
       "    <table border=\"1\"><tr><td>&ensp;</td><td>x</td><td>o</td></tr><tr><td>&ensp;</td><td>x</td><td>&ensp;</td></tr><tr><td>&ensp;</td><td>x</td><td>o</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross won\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "from tic_tac_toe.Board import Board, GameResult, CROSS, NAUGHT, EMPTY\n",
    "from util import print_board, play_game\n",
    "from tic_tac_toe.RandomPlayer import RandomPlayer\n",
    "\n",
    "board = Board()\n",
    "player1 = RandomPlayer()\n",
    "player2 = RandomPlayer()\n",
    "\n",
    "result = play_game(board, player1, player2)\n",
    "print_board(board)\n",
    "\n",
    "if result == GameResult.CROSS_WIN:\n",
    "    print(\"Cross won\")\n",
    "elif result == GameResult.NAUGHT_WIN:\n",
    "    print(\"Naught won\")\n",
    "else:\n",
    "    print(\"Draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Min-Max algorithm\n",
    "So, what is this Min-Max algorithm that we want to implement?\n",
    "\n",
    "The long answer can be found [here](https://en.wikipedia.org/wiki/Minimax). We won't go into that much detail here and just look at the general idea:\n",
    "\n",
    "Given a board state, we find the best move by simulating all possible continuations from this position and chose the one that is best for us. The one best for us is the one with the best outcome if:\n",
    "\n",
    "* we always make the move that is best for us (*Maximizes* the game value for us) and \n",
    "* our opponent always makes the move that is best for them (and thus worst for us - *Minimizing* the game value for us). \n",
    "\n",
    "You can see where the algorithm gets its name from.\n",
    "\n",
    "Let's look at an exmaple. Given the followin board position and NAUGHT to move next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "      border: 1px  black solid !important;\n",
       "      color: black !important;\n",
       "    }\n",
       "    </style>\n",
       "    <table border=\"1\"><tr><td>x</td><td>&ensp;</td><td>x</td></tr><tr><td>o</td><td>o</td><td>x</td></tr><tr><td>&ensp;</td><td>&ensp;</td><td>o</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = Board([CROSS  , EMPTY  , CROSS,\n",
    "                 NAUGHT , NAUGHT , CROSS,\n",
    "                 EMPTY  , EMPTY  , NAUGHT])\n",
    "print_board(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following continuations are possible:\n",
    "![title](./TicTacToe-MinMax-Example1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is: first NAUGHT, the maximizing player, gets to move, then CROSS, the minimizing player, gets to move and in those cases where the game has not ended at that point, NAUGHT, the maximizing player, gets one more move:\n",
    "![title](./TicTacToe-MinMax-Example2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label all final game states according to their value from the point of view of Naught: \n",
    "* 1 for a win\n",
    "* -1 for a loss\n",
    "* 0 for a draw\n",
    "\n",
    "![title](./TicTacToe-MinMax-Example3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can back propagate the scores from the bottom layer to the layer above. According to the algorithm, as it is the Max players turn, we chose the move with the highest score. Note that in this initial case, as there is only one possible move and the move thus is forced, we just propagate that value one layer up without having to chose a maximizing move:\n",
    "\n",
    "![title](./TicTacToe-MinMax-Example4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we propagate up again. This time it is the minimizing player's turn, so we propagate the smaller values for each possible move up:\n",
    "\n",
    "![title](./TicTacToe-MinMax-Example5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we propagate one more layer up. This time it's the maximizing player again, so we chose the highest possible value of all moves for the position:\n",
    "\n",
    "![title](./TicTacToe-MinMax-Example6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know everything we need to know to make a move: \n",
    "\n",
    "* The best we can hope for if both we and our opponent always plays their best move is a draw (since the score of the current board position is 0). \n",
    "\n",
    "* We also know, there is only 1 move in the current situation that will achieve this best case for us: Putting a NAUGHT in the middle spot on the top row.\n",
    "\n",
    "Note that there are other potential continuation that would also lead to a draw, and even some that might lead to NAUGHT winning. Unfortunately, however we also know now that if CROSS always plays their best move we won't ever have a chance to get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Min-Max players ##\n",
    "The code contains the following 2 player classes which implement the MinMax algorithm for TicTacToe. \n",
    "\n",
    "In order to make things a bit more efficient the players will remember the scores for a given board position in an internal cache. This means it has to simulate the possible continuation from that position only once. It makes even this first simluation more efficient as often different move combination could produce the same board position, which, with the cached result we don't have to evaluate again.\n",
    "\n",
    "Even on a moderately fast computer this works quite well due to the small number of possible board positions in Tic Tac Toe: While a game can have something like $9! = 362,800$ different possible move combinations, i.e. 9 choices for the first move, 8 choices for the second move, 7 choices for the 3rd move etc down to 1 choice for the last move (and for simpicity ignoring cases where the game is over before all squares a occupied), the game can only have $3^9 = 19,683$ different states as each square can only either be empty, have a NAUGHTp, or have a CROSS in it (again for simplicity ignoring game states that are impossible in a real game; also ignoring the fact that we could reduce the number of states further by treating symmetirc position as the same). \n",
    "\n",
    "* [MinMaxAgent.py](./tic_tac_toe/MinMaxAgent.py): Plays Tic Tac Toe using the MinMax Algorithm in a deterministic way. I.e. if there are more than 1 moves with euqal best scores in a given position this pplayer will always chose the same one.\n",
    "\n",
    "* [RndMinMaxAgent.py](./tic_tac_toe/RndMinMaxAgent.py): Plays Tic Tac Toe using the MinMax Algorithm in a non-deterministic way. I.e. if there are more than 1 moves with euqal best scores in a given position this pplayer will randomly chose one of them each time.\n",
    "\n",
    "Let's see how they perform.\n",
    "\n",
    "First we define a small utility function to pit 2 players against each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tic_tac_toe.Player import Player\n",
    "\n",
    "def battle(player1: Player, player2: Player, num_games : int = 100000 ) :\n",
    "    draw_count = 0\n",
    "    cross_count = 0\n",
    "    naught_count = 0\n",
    "    for _ in range(num_games):\n",
    "        result = play_game(board, player1, player2)\n",
    "        if result == GameResult.CROSS_WIN:\n",
    "            cross_count += 1\n",
    "        elif result == GameResult.NAUGHT_WIN:\n",
    "            naught_count += 1\n",
    "        else:\n",
    "            draw_count += 1\n",
    "        \n",
    "    print(\"After {} game we have draws: {}, cross wins: {}, and naught wins: {}.\".format(num_games, draw_count, \n",
    "                                                                        cross_count, naught_count))\n",
    "\n",
    "    print(\"Which gives percentages of draws : cross : naught of about {:.2%} : {:.2%} : {:.2%}\".format(\n",
    "        draw_count / num_games, cross_count / num_games, naught_count / num_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First MinMaxAgent against RandomPlayer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MinMaxAgent' object has no attribute 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-38c9afe93087>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtic_tac_toe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxAgent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbattle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMinMaxAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomPlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-bd0078a2de78>\u001b[0m in \u001b[0;36mbattle\u001b[1;34m(player1, player2, num_games)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnaught_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_games\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mGameResult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCROSS_WIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mcross_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carsten\\PycharmProjects\\tic-tac-toe\\util.py\u001b[0m in \u001b[0;36mplay_game\u001b[1;34m(board, player1, player2)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mfinished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfinished\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfinished\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mGameResult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDRAW\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carsten\\PycharmProjects\\tic-tac-toe\\tic_tac_toe\\MinMaxAgent.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(self, board)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinished\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\carsten\\PycharmProjects\\tic-tac-toe\\tic_tac_toe\\MinMaxAgent.py\u001b[0m in \u001b[0;36m_max\u001b[1;34m(self, board)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# of a draw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mmax_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDRAW_VALUE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MinMaxAgent' object has no attribute 'self'"
     ]
    }
   ],
   "source": [
    "from tic_tac_toe.MinMaxAgent import MinMaxAgent\n",
    "\n",
    "battle(MinMaxAgent(), RandomPlayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
