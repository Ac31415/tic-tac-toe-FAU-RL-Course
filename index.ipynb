{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teaching a computer how to play Tic Tac Toe\n",
    "\n",
    "\n",
    "\n",
    "## From classic algorithms to Reinforcement learning with Neural Networks\n",
    "\n",
    "In this series of articles and Jupyter notebooks we will explore a number of different approaches, from Min Max to Neural Networks, to teach or train a computer how to play the famous board game [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "\n",
    "Most people will be familiar with [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe)\n",
    "    and more than likely you will have played it at some stage of their life. \n",
    "\n",
    "The game is rather simple. With respect to its rules as well as its strategy. In fact, it can be played by\n",
    "    young children and a Tic Tac Toe board can often be found at playgrounds:\n",
    "\n",
    "![Title](./Images/tic-tac-toe-355090_640.jpg)\n",
    "\n",
    "[Source](https://pixabay.com/en/tic-tac-toe-game-tick-tack-toe-355090)\n",
    "\n",
    "\n",
    "If you have played Tic Tac Toe a couple of times you will have quickly realized that it is quite easy to master.\n",
    "    You will most likely also have discovered that when both players play good moves, the game will always end in a\n",
    "    draw.\n",
    "\n",
    "In the following, we will use the example of\n",
    "    Tic Tac Toe to look at various approaches which can be used to teach or train a computer to play this game. Not because Tic Tac Toe is\n",
    "    particularly challenging, but because it gives us a consistent, easy to understand target.\n",
    "\n",
    "\n",
    "We will look at\n",
    "    the classic Min Max algorithm, a tabular reinforcement learning approach\n",
    "    as well as a couple of Neural Network based reinforcement learning approaches:\n",
    "    \n",
    "* [Part 1 - Computer Tic Tac Toe Basics](Part 1 - Computer Tic Tac Toe Basics.ipynb)\n",
    "* [Part 2 - The Min Max Algorithm](Part 2 - The Min Max Algorithm.ipynb) \n",
    "* [Part 3 - Tabular Q-Learning](Part 3 - Tabular Q-Learning.ipynb)\n",
    "* [Part 4 - Neural Network Q-Learning](Part 4 - Neural Network Q-Learning.ipynb)\n",
    "* [Part 5 - Q Network review and becoming less greedy](Part 5 - Q Network review and becoming less greedy.ipynb)\n",
    "* [Part 6 - Double Duelling Q Network with Experience Replay](Part 6 - Double Duelling Q Network with Experience Replay.ipynb)\n",
    "* [Part 7 - This is deep. In a convoluted way](Part 7 - This is deep. In a convoluted way.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
